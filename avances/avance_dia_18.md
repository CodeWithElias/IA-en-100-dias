# ğŸ“… DÃ­a 18: ValidaciÃ³n de modelos

## ğŸ“Œ Â¿QuÃ© es la validaciÃ³n de modelos?
Es el proceso de evaluar el rendimiento de un modelo de machine learning con datos que **no ha visto antes**, con el objetivo de estimar su capacidad de **generalizaciÃ³n**. Es crucial para evitar **sobreajuste (overfitting)** o **subajuste (underfitting)**.

---

## ğŸ” TÃ©cnicas de validaciÃ³n mÃ¡s comunes

### 1. Hold-Out
- Divide el conjunto de datos en dos partes: entrenamiento y prueba (por ejemplo 80/20).
- Simple, pero depende de quÃ© datos caigan en cada parte.

### 2. ValidaciÃ³n cruzada (Cross-Validation)
- Divide el conjunto en â€œkâ€ partes iguales (llamadas folds).
- Se entrena el modelo con k-1 partes y se prueba con la restante.
- Repite el proceso k veces cambiando el fold de prueba.
- Finalmente se promedian los resultados.

#### â• Ventajas:
- Usa todos los datos para entrenamiento y prueba (en distintos momentos).
- Menos varianza en los resultados.

---

## ğŸ” Â¿QuÃ© es K-Fold Cross-Validation?
- TÃ©cnica de validaciÃ³n cruzada en la que el conjunto se divide en **k subconjuntos (folds)**.
- Se entrena el modelo k veces, cada vez dejando un fold distinto como conjunto de prueba.
- Se calcula la media de las mÃ©tricas de rendimiento (precisiÃ³n, F1, etc.).

---

## ğŸ§ª Ejemplo en Python

```python
from sklearn.datasets import load_iris
from sklearn.model_selection import cross_val_score, KFold
from sklearn.linear_model import LogisticRegression
import numpy as np

# Cargamos el dataset Iris
X, y = load_iris(return_X_y=True)

# Creamos el modelo
modelo = LogisticRegression(max_iter=200)

# Definimos KFold con 5 particiones
kfold = KFold(n_splits=5, shuffle=True, random_state=42)

# Aplicamos validaciÃ³n cruzada
resultados = cross_val_score(modelo, X, y, cv=kfold)

print("Resultados por fold:", resultados)
print("PrecisiÃ³n promedio:", np.mean(resultados))
```

---

## ğŸ“ˆ InterpretaciÃ³n
- Se entrena el modelo 5 veces.
- Cada vez se evalÃºa con un fold diferente.
- El resultado final es la media de los 5 resultados â†’ una **estimaciÃ³n mÃ¡s confiable** de cÃ³mo se comportarÃ¡ el modelo con nuevos datos.

---

## âš ï¸ Â¿Por quÃ© es importante?
- Evita depender de un Ãºnico conjunto de prueba.
- Nos ayuda a elegir el mejor modelo y a ajustar sus hiperparÃ¡metros.
- Mide si el modelo estÃ¡ sobreajustando (si tiene rendimiento excelente solo en los datos de entrenamiento).