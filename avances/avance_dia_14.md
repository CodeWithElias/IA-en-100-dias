
# 游늰 D칤a 14: Random Forest en el Reto de 100 d칤as de IA

## 游 쯈u칠 es Random Forest?

Random Forest (Bosque Aleatorio) es un algoritmo de aprendizaje supervisado que combina m칰ltiples 치rboles de decisi칩n para obtener una predicci칩n m치s robusta y precisa.

- Se basa en el principio del **ensamble learning**, espec칤ficamente del m칠todo **bagging**.
- Entrena m칰ltiples 치rboles de decisi칩n sobre subconjuntos aleatorios del conjunto de entrenamiento.
- Luego combina los resultados de cada 치rbol (por mayor칤a para clasificaci칩n, promedio para regresi칩n).

---

## 游댌 쯇or qu칠 usar Random Forest?

- Reduce el sobreajuste (overfitting) comparado con un solo 치rbol.
- Mejora la precisi칩n del modelo.
- Es robusto ante valores at칤picos y datos faltantes.
- Muy utilizado en clasificaci칩n y regresi칩n.

---

## 游 Comparaci칩n con 츼rboles de Decisi칩n

| Caracter칤stica        | 츼rbol de Decisi칩n        | Random Forest             |
|-----------------------|--------------------------|---------------------------|
| Modelo                | 칔nico 치rbol              | Conjunto de 치rboles       |
| Precisi칩n             | Menor (puede sobreajustar)| Mayor precisi칩n           |
| Interpretabilidad     | Alta                     | Media (menos interpretable)|
| Riesgo de sobreajuste| Alto                     | Bajo                      |

---

## 游댢 Implementaci칩n b치sica en Python

```python
# Importamos las bibliotecas necesarias
import numpy as np  # Para manejo de arreglos num칠ricos
import matplotlib.pyplot as plt  # Para graficar
from sklearn.ensemble import RandomForestClassifier  # Modelo de Random Forest para clasificaci칩n
from sklearn.model_selection import train_test_split  # Para dividir datos en entrenamiento y prueba
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report  # M칠tricas de evaluaci칩n

# Creamos los datos de entrada (edad del usuario) y las etiquetas (0 = no compr칩, 1 = compr칩)
x = np.array([
    [18], [20], [22], [25], [28], [30], [32], [35], [38], [40],
    [42], [45], [48], [50], [52], [55], [58], [60], [62], [65]
])
y = np.array([
    0, 0, 0, 1, 1, 1, 1, 1, 1, 1,  # Datos donde se asume que edades mayores tienden a comprar m치s
    0, 0, 1, 1, 0, 0, 0, 1, 1, 1
])

# Dividimos los datos en conjuntos de entrenamiento y prueba (80% entrenamiento, 20% prueba)
x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)

# Creamos un modelo de Random Forest con 100 치rboles y profundidad m치xima de 5
modelo = RandomForestClassifier(n_estimators=100, max_depth=5, random_state=42)
modelo.fit(x_train, y_train)  # Entrenamos el modelo con los datos de entrenamiento

# -------- Predicci칩n simple para una nueva edad ----------
nueva_edad = [[29]]  # Queremos predecir si una persona de 29 a침os comprar치
pred = modelo.predict(nueva_edad)  # Predicci칩n de clase (0 o 1)
prob = modelo.predict_proba(nueva_edad)[0][1]  # Probabilidad de que compre (clase 1)

# Mostramos el resultado de la predicci칩n
print(f"쯋na persona de 29 a침os comprar치 el producto? {'S칤' if pred[0] == 1 else 'No'}")
print(f"Probabilidad de compra: {prob:.2f}")  # Mostramos la probabilidad con 2 decimales

# -------- Evaluaci칩n del modelo ----------
y_pred = modelo.predict(x_test)  # Predecimos con los datos de prueba

# Imprimimos m칠tricas de evaluaci칩n del modelo
print("\n--- Evaluaci칩n del modelo ---")
print("Accuracy:", accuracy_score(y_test, y_pred))  # Precisi칩n: porcentaje de aciertos
print("Matriz de confusi칩n:\n", confusion_matrix(y_test, y_pred))  # Muestra TP, FP, FN, TN
print("Reporte de clasificaci칩n:\n", classification_report(y_test, y_pred))  # Precisi칩n, recall y F1-score

# -------- Gr치fica de probabilidades para un rango de edades ----------
x_range = np.linspace(18, 65, 100).reshape(-1, 1)  # Creamos un rango de edades entre 18 y 65
probs = modelo.predict_proba(x_range)[:, 1]  # Calculamos la probabilidad de compra para cada edad

# Graficamos los resultados
plt.figure(figsize=(10, 6))  # Tama침o del gr치fico
plt.plot(x_range, probs, label="Probabilidad de compra", color="green")  # L칤nea de probabilidad
plt.scatter(x, y, color="blue", label="Datos reales")  # Puntos originales del dataset
plt.xlabel("Edad")  # Etiqueta del eje X
plt.ylabel("Probabilidad de compra")  # Etiqueta del eje Y
plt.title("Probabilidad de compra vs Edad (Random Forest)")  # T칤tulo del gr치fico
plt.legend()  # Muestra las leyendas
plt.grid(True)  # Agrega una cuadr칤cula al fondo
plt.show()  # Muestra la gr치fica

```

---

## 游늳 Evaluaci칩n del modelo

Puedes usar `.score()`, `confusion_matrix` o `classification_report` para evaluar el modelo en conjunto de prueba.

---

## 游닄 Recursos 칰tiles

- [Documentaci칩n oficial de Scikit-learn - Random Forest](https://scikit-learn.org/stable/modules/ensemble.html#random-forests)
- [Video educativo sobre Random Forest (YouTube)](https://www.youtube.com/watch?v=J4Wdy0Wc_xQ)

---

## 游빍 Ejercicio sugerido

Entrena un modelo `RandomForestClassifier` con un conjunto de datos m치s grande. Luego:
1. Eval칰a la precisi칩n.
2. Compara con un 치rbol de decisi칩n simple.
3. Visualiza la importancia de cada caracter칤stica con `.feature_importances_`.

---

춰Sigue adelante con el reto! 游